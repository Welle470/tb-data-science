# Проект 3. Проект: классификация. 

## Оглавление

[1. Описание проекта](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Описание-проекта)

[2. Какой кейс решаем](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Какой-кейс-решаем)

[3. Краткая информация о данных](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Краткая-информация-о-данных)

[4. Этапы работы над проектом](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Этапы-работы-над-проектом)

[5. Графики](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Графики)

[6. Результат](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Результат)

[6. Выводы](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Выводы)

### Описание проекта

Предоставленные данные о последней маркетинговой кампании, которую проводил банк: задачей было привлечь клиентов для открытия депозита. Следует проанализировать эти данные, выявить закономерность и найти решающие факторы, повлиявшие на то, что клиент вложил деньги именно в этот банк. Если получится это сделать - поднимутся доходы банка и можно будет понять целевую аудиторию, которую необходимо привлекать путём рекламы и различных предложений.


:arrow_up: [к оглавлению](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Оглавление)

### Какой кейс решаем

Построить модель машинного обучения, которая на основе предложенных характеристик клиента будет предсказывать, воспользуется он предложением об открытии депозита или нет.


**Проект состоит из 5 частей:**
- Первичная обработка данных (В рамках этой части предстоит обработать пропуски и выбросы в данных. Это необходимо для дальнейшей работы с ними);
- Разведывательный анализ данных (EDA) (Необходимо будет исследовать данные, нащупать первые закономерности и выдвинуть гипотезы);
- Отбор и преобразование признаков (На этом этапе нужно перекодировать и преобразовать данные таким образом, чтобы их можно было использовать при решении задачи классификации);
- Решение задачи классификации: логистическая регрессия и решающие деревья (На данном этапе построить первую прогностическую модель и оцените её качество. Подобрать оптимальные параметры модели для того, чтобы получить наилучший результат для конкретного алгоритма);
- Решение задачи классификации: ансамбли моделей и построение прогноза (На заключительном этапе следует доработать своё предсказание с использованием более сложных алгоритмов и оценить, с помощью какой модели возможно сделать более качественные прогнозы);

:arrow_up: [к оглавлению](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Оглавление)

### Краткая информация о данных
Данные о клиентах банка:
- age (возраст);
- job (сфера занятости);
- marital (семейное положение);
- education (уровень образования);
- default (имеется ли просроченный кредит);
- housing (имеется ли кредит на жильё);
- loan (имеется ли кредит на личные нужды);
- balance (баланс).

Данные, связанные с последним контактом в контексте текущей маркетинговой кампании:
- contact (тип контакта с клиентом);
- month (месяц, в котором был последний контакт);
- day (день, в который был последний контакт);
- duration (продолжительность контакта в секундах).

Прочие признаки:
- campaign (количество контактов с этим клиентом в течение текущей кампании);
- pdays (количество пропущенных дней с момента последней маркетинговой кампании до контакта в текущей кампании);
- previous (количество контактов до текущей кампании)
- poutcome (результат прошлой маркетинговой кампании).

И, разумеется, целевая переменная deposit, которая определяет, согласится ли клиент открыть депозит в банке. Именно её мы будем пытаться предсказать в данном кейсе.


:arrow_up: [к оглавлению](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Оглавление)

### Этапы работы над проектом
1. Знакомство с данными
2. Обработка пропусков
3. Преобразование признаков
4. Удаление выбросов
5. Разведывательный анализ данный, диаграммы 
6. Преобразование данных
7. Кодирование признаков
8. Постоянение матрицы корреляций
9. Отбор 15 наиболее подходящих признаков
10. Нормализация данных
11. Обучение логистической регрессии
12. Обучение решающих деревьев
13. Подбор оптимальный параметров с GridSearchCV
14. Обучение случайного леса
15. Использование градиентного бустинга
16. Объединение всех алгоритмов с помощью стекинга
17. Оценка важности признаков
18. Выводы


:arrow_up: [к оглавлению](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Оглавление)

### Графики
1. Распределение целевой переменной
2. Описательные статистики для количественных переменных
3. Зависимость между открытием депозита и возрастом
4. Распределение целевого признака по дням месяца
5. Распределение целевого признака и продолжительности контакта в секундах
6. Распределение целевого признака и количества контактов с этим клиентом в течение текущей кампании
7. Распределение количество контактов по месяцам
8. Количество сфер занятости среди клиентов банка
9. Семейное положение среди клиентов банка
10. Уровень образования среди клиентов
11. Наличие кредита на жилье среди клиентов банка
12. Зависимость открытия депозита от возрастной группы
13. Распределение открытия депозита по семейному положению
14. Распределение открытия депозита по образованию
15. Распределение открытия депозита в зависимости от профессии
16. Тепловая карта количество клиентов открывших и неоткрывших депозит
17. Корреляционная матрица 
18. ТОП-10 признаков градиентного бустинга

:arrow_up: [к оглавлению](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Оглавление)

### Результат
1. Знакомство с данными:
- Был получен исходный датасет с информацией о клиентах банка и их отклике на маркетинговую кампанию.
2. Обработка пропусков:
- Проведена проверка наличия пропущенных значений в данных.
- Пропущенные значения были обработаны.
3. Преобразование признаков:
- Проведено преобразование категориальных признаков в числовой формат.
- Некоторые признаки были преобразованы для лучшей интерпретации данных, например, возраст был разделен на возрастные группы.
4. Удаление выбросов:
- Выполнено удаление выбросов из числовых признаков с использованием межквартильного размаха.
5. Разведывательный анализ данных, диаграммы:
- Был проведен разведывательный анализ данных для выявления распределения признаков, зависимостей между ними и выявления закономерностей.
- Использованы различные типы диаграмм, такие как столбчатые диаграммы, гистограммы, корреляционные матрицы и тепловые карты для визуализации данных.
6. Преобразование данных:
- Проведено масштабирование данных для улучшения работы алгоритмов с помощью метода Min-Max Scaling.
7. Кодирование признаков:
- Произведено кодирование категориальных признаков для использования их в моделях машинного обучения.
8. Построение матрицы корреляций:
- Построена корреляционная матрица, которая позволила оценить взаимосвязь между признаками.
9. Отбор 15 наиболее подходящих признаков:
- Был произведен отбор наиболее значимых признаков для улучшения производительности моделей.
10. Нормализация данных:
- Для повышения качества работы моделей была выполнена нормализация данных.
11. Обучение логистической регрессии:
- Произведено обучение логистической регрессии на обработанных данных.
- Получены значения метрик качества (accuracy, precision, recall, F1-score) на тестовой и обучающей выборке.
12. Обучение решающих деревьев:
- Обучены решающие деревья с различными глубинами на обработанных данных.
- Рассчитаны метрики качества для каждого варианта модели.
13. Подбор оптимальных параметров с GridSearchCV:
- Произведен подбор оптимальных гиперпараметров для решающих деревьев с помощью GridSearchCV.
- Получены оптимальные значения параметров и метрики качества для лучшего варианта.
14. Обучение случайного леса:
- Обучен случайный лес с подобранными оптимальными гиперпараметрами.
- Рассчитаны значения метрик качества на тестовой и обучающей выборке.
15. Использование градиентного бустинга:
- Обучен градиентный бустинг с заданными параметрами.
- Рассчитаны метрики качества на тестовой и обучающей выборке.
16. Объединение всех алгоритмов с помощью стекинга:
- Построена стекинг модель, объединяющая лучшие алгоритмы.
- Получены значения метрик качества на тестовой и обучающей выборке для стекинга.
17. Оценка важности признаков:
- Проведена оценка важности признаков для каждого алгоритма.
- Измерена важность признаков влияющих на результаты моделей.
18. Выводы:
- Проведен обширный анализ данных и подготовка данных для построения моделей.
- Были сравнены различные алгоритмы машинного обучения и определены наилучшие варианты для данной задачи.

:arrow_up: [к оглавлению](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Оглавление)

### Выводы
Данный проект представляет собой исследование данных банковской маркетинговой кампании с использованием различных алгоритмов машинного обучения.

Результаты исследования позволяют сделать следующие выводы:
- Важность удержания лояльных клиентов: клиенты, которые успешно участвовали в предыдущих кампаниях, представляют значимую группу, на которую стоит ориентироваться в новых маркетинговых усилиях.

- Неизвестные типы контакта и результаты предыдущих кампаний могут оказать негативное влияние на результаты. Необходимо уделить внимание тщательному планированию контактных методов и регулярной отслеживанию информации о предыдущих кампаниях.

- Случайный лес с оптимальными гиперпараметрами продемонстрировал наилучшее качество предсказаний на тестовой выборке.

- Объединение лучших алгоритмов с помощью стекинга позволяет немного улучшить результаты.

- Данные выводы могут быть использованы для планирования будущих маркетинговых кампаний и оптимизации работы с клиентами банка.

:arrow_up: [к оглавлению](https://github.com/Welle470/df-data-science/blob/master/project4/README.md#Оглавление)
